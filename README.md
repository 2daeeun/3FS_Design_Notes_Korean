[Deepseek AI에서 개발한 3FS(Fire-Flyer File System)의 Design Notes](https://github.com/deepseek-ai/3FS/blob/main/docs/design_notes.md)의 내용을 한국어로 번역한 문서입니다.
(2025년 3월 1일 기준)

  
# 설계 노트

## 설계 및 구현

3FS 시스템은 클러스터 관리자, 메타데이터 서비스, 스토리지 서비스, 그리고 클라이언트의 네 가지 구성 요소로 이루어져 있다. 모든 구성 요소는 RDMA 네트워크(InfiniBand 또는 RoCE)에 연결된다.

메타데이터 서비스와 스토리지 서비스는 클러스터 관리자에게 하트비트를 전송한다. 클러스터 관리자는 멤버십 변경을 처리하고 클러스터 구성을 다른 서비스와 클라이언트에게 배포한다. 여러 대의 클러스터 관리자가 배치되며 그 중 하나가 기본(primary)으로 선출된다. 기본 관리자에 장애가 발생하면 다른 관리자가 기본으로 승격된다. 클러스터 구성은 일반적으로 ZooKeeper나 etcd와 같은 신뢰할 수 있는 분산 조정 서비스에 저장된다. 우리의 프로덕션 환경에서는 의존성을 줄이기 위해 파일 메타데이터와 동일한 키-값 저장소를 사용한다.

파일 메타데이터 작업(예: 파일/디렉토리 열기 또는 생성)은 파일 시스템의 의미론을 구현하는 메타데이터 서비스로 전송된다. 파일 메타데이터는 트랜잭셔널 키-값 저장소(예: FoundationDB)에 저장되기 때문에 메타데이터 서비스는 상태 비저장(stateless)이다. 클라이언트는 임의의 메타데이터 서비스에 연결할 수 있다.

각 스토리지 서비스는 몇 개의 로컬 SSD를 관리하며 청크 스토어 인터페이스를 제공한다. 스토리지 서비스는 강력한 일관성을 보장하기 위해 할당된 쿼리(아포션 쿼리)를 사용하는 체인 복제(CRAQ)를 구현한다. CRAQ의 “모두 쓰고 어느 곳에서나 읽기” 접근 방식은 SSD와 RDMA 네트워크의 처리량을 최대한 활용하는 데 도움을 준다. 3FS 파일은 동일한 크기의 청크들로 분할되며, 이 청크들은 여러 SSD에 복제되어 저장된다.

애플리케이션을 위해 두 종류의 클라이언트가 개발되었다: FUSE 클라이언트와 네이티브 클라이언트. 대부분의 애플리케이션은 낮은 진입 장벽을 가진 FUSE 클라이언트를 사용한다. 성능이 중요한 애플리케이션은 네이티브 클라이언트를 통합하여 사용한다.

## 파일 시스템 인터페이스

객체 스토어는 데이터 분석과 머신 러닝을 위한 인기 있는 옵션이 되어가고 있다. 그러나 파일 시스템의 의미론과 파일이 디렉토리 내에 조직되는 통합 네임스페이스는 애플리케이션에 더 큰 유연성을 제공한다.

-   *원자적 디렉토리 조작*  
    객체 스토어는 객체 키에 슬래시(/)를 사용하여 계층적 디렉토리 구조를 흉내 낼 수 있다. 그러나 파일이나 디렉토리를 원자적으로 이동시키거나 전체 디렉토리를 재귀적으로 삭제하는 등의 작업은 기본적으로 지원하지 않는다. 실제로 내부 애플리케이션에서 흔히 사용되는 패턴은 임시 디렉토리를 생성한 후, 그곳에 파일들을 쓰고, 최종 위치로 디렉토리를 이동시키는 것이다. 소규모 파일이 많은 경우 디렉토리에 대한 재귀적 삭제가 매우 중요하다. 이를 지원하지 않으면 애플리케이션은 각 디렉토리를 순회하며 파일을 하나씩 삭제해야 한다.

-   *심볼릭 링크 및 하드 링크*  
    우리의 애플리케이션은 동적으로 업데이트되는 데이터셋의 경량 스냅샷을 생성하기 위해 심볼릭 링크와 하드 링크를 활용한다. 새로운 데이터는 개별 파일로 추가된다.

-   *익숙한 인터페이스*  
    파일 인터페이스는 널리 알려져 있으며 어디에서나 사용된다. 새로운 스토리지 API를 배울 필요가 없다. 많은 데이터셋이 CSV 또는 Parquet 파일 형식으로 저장되어 있다. 파일 기반 데이터 로더를 3FS FUSE 클라이언트나 네이티브 클라이언트를 사용하도록 적응시키는 것은 간단하다.

### FUSE의 한계

FUSE(Filesystem in Userspace)는 FUSE 커널 모듈을 통해 I/O 작업을 사용자 공간 프로세스로 전환함으로써 파일 시스템 클라이언트 개발을 단순화한다. 이는 애플리케이션이 원격 파일 시스템에 로컬 파일 시스템처럼 접근하는 착시를 만들어낸다. 그러나 다음과 같은 성능 제한이 있다:

-   *메모리 복사 오버헤드*  
    사용자 공간의 파일 시스템 데몬은 애플리케이션 메모리에 접근할 수 없다. 커널과 사용자 공간 간 데이터 전송은 메모리 대역폭을 소모하며 엔드 투 엔드 지연 시간을 증가시킨다.

-   *미흡한 멀티스레딩 지원*  
    애플리케이션이 I/O 요청을 시작하면, FUSE는 이 요청들을 스핀락으로 보호되는 다중 스레드 공유 큐에 넣는다. 이후 사용자 공간의 파일 시스템 데몬이 이 큐에서 요청들을 가져와 처리한다. 락 경합으로 인해 FUSE의 I/O 처리 능력은 스레드 수에 따라 확장되지 않는다. 벤치마크 결과에 따르면 FUSE는 대략 400K의 4KiB 읽기 작업만 처리할 수 있다. 동시성이 더 높아져도 락 경합이 심해지면서 성능 향상이 이루어지지 않는다. `perf` 프로파일링 결과, 커널 공간의 스핀락이 상당한 CPU 시간을 소모하는 것으로 나타났다.

대부분의 애플리케이션(예: 데이터 분석)은 3FS에서 큰 블록 단위의 쓰기를 수행하거나, 메모리에 데이터를 버퍼링한 후 쓰기 버퍼가 가득 찼을 때 3FS에 플러시한다. 그러나 Linux 5.x의 FUSE는 동일 파일에 대한 동시 쓰기를 지원하지 않는다[^1]. 애플리케이션은 이 한계를 극복하기 위해 여러 파일에 동시 쓰기를 수행하여 전체 처리량을 최대화한다.

읽기 작업은 더 복잡한 패턴을 보인다. 일부 학습 작업은 데이터셋 샘플에 대해 몇 킬로바이트에서 수 메가바이트까지 다양한 크기의 랜덤 접근을 요구한다. 또한 파일 내의 샘플은 일반적으로 4K 정렬이 되어 있지 않다. 데이터 로더는 배치 단위의 샘플을 가져오도록 특별히 설계되어 있다. 그러나 FUSE로 마운트된 3FS에서 소규모 랜덤 읽기를 처리할 때 성능이 저하된다. SSD와 RDMA 네트워크의 대역폭이 충분히 활용되지 않는다.

### 비동기 제로 카피 API

파일 시스템 클라이언트를 VFS 커널 모듈로 구현하면 위에서 언급한 성능 문제를 회피할 수 있다. 그러나 커널 모듈 개발은 사용자 공간 시스템 프로그래밍보다 훨씬 더 어려우며, 버그 진단이 힘들고 프로덕션 환경에서 치명적인 실패를 야기할 수 있다. 예를 들어, 머신이 크래시가 나면 디버깅을 위한 로그 메시지가 남지 않을 수 있다. 커널 모듈을 업그레이드할 때는 파일 시스템을 사용하는 모든 프로세스를 깔끔하게 중지시켜야 하며, 그렇지 않으면 머신 재시작이 필요하다.

이러한 이유로 우리는 FUSE 데몬 내에 네이티브 클라이언트를 구현하기로 선택하였다. 이 클라이언트는 비동기 제로 카피 I/O 작업을 지원하는 인터페이스를 제공한다. 파일 메타 작업(예: 파일 열기/닫기/상태 조회)은 여전히 FUSE 데몬에서 처리된다. 애플리케이션은 `open()`을 호출하여 파일 디스크립터(fd)를 획득한 후, 네이티브 API를 통해 이를 등록한다. 이후 네이티브 클라이언트를 사용하여 파일에 대한 I/O 작업을 수행할 수 있다. 이 접근 방식은 POSIX API와의 메타데이터 작업 일관성을 보장하여 기존 코드를 마이그레이션하기 쉽게 만든다.

비동기 제로 카피 API는 Linux의 `io_uring`에서 영감을 받았다. 아래는 API의 주요 데이터 구조이다:

-   *Iov*  
    사용자 프로세스와 네이티브 클라이언트 간 제로 카피 읽기/쓰기 작업을 위해 공유되는 큰 메모리 영역이다. InfiniBand 메모리 등록은 클라이언트에서 관리된다. 네이티브 API에서는 모든 읽기 데이터가 Iov로 읽혀지며, 모든 쓰기 데이터는 API 호출 전에 Iov에 기록되어야 한다.

-   *Ior*  
    사용자 프로세스와 네이티브 클라이언트 간 통신을 위한 작은 공유 링 버퍼이다. Ior의 사용 방식은 Linux의 `io_uring`과 유사하여, 사용자 프로세스가 읽기/쓰기 요청을 큐에 넣으면 네이티브 클라이언트가 해당 요청들을 꺼내어 완료시키는 방식이다. 요청들은 `io_depth` 파라미터에 의해 제어되는 크기로 배치되어 처리된다. 여러 배치가 동시에 처리될 수 있는데, 이는 다른 링 버퍼이거나 동일한 링 버퍼에서 발생한다. 다만, 링 버퍼를 공유하면 동기화가 필요해지므로, 다중 스레드 애플리케이션에서는 여러 링 버퍼를 사용하는 것이 권장된다.

네이티브 클라이언트 내에서는 여러 스레드가 생성되어 Ior에서 I/O 요청을 가져온다. 이 요청들은 배치 처리되어 스토리지 서비스로 전달되며, 이를 통해 소규모 읽기 요청으로 인한 RPC 오버헤드를 줄인다.

## 파일 메타데이터 저장소

### 파일 청크의 위치

3FS는 파일 데이터를 동일한 크기의 청크로 나누어 여러 복제 체인에 스트라이프 방식으로 배치한다(복제 체인과 체인 테이블에 대한 정의는 [데이터 배치](#데이터-배치)) 섹션에 설명되어 있다). 사용자는 디렉토리 단위로 파일에 대해 체인 테이블, 청크 크기, 스트라이프 크기를 지정할 수 있다. 각 청크는 독립적으로 여러 스토리지 서비스에 저장되며, 해당 청크의 ID는 파일의 inode id와 청크 인덱스를 연결하여 생성된다.

새 파일을 생성할 때, 메타데이터 서비스는 지정된 체인 테이블에서 스트라이프 크기에 따라 연속적인 복제 체인을 선택하기 위해 라운드로빈 전략을 사용한다. 이후 선택된 체인들을 섞기 위해 임의의 시드가 생성된다. 이러한 할당 전략은 체인과 SSD 전반에 걸쳐 데이터가 균형 있게 분산되도록 보장한다.

애플리케이션이 파일을 열면, 클라이언트는 메타 서비스에 접속하여 파일의 데이터 레이아웃 정보를 획득한다. 이후 클라이언트는 메타 서비스의 개입을 최소화한 채, 독립적으로 데이터 작업을 위한 청크 ID와 체인을 계산할 수 있다.

### 트랜잭셔널 키-값 저장소에 저장된 파일 메타데이터

3FS는 메타데이터를 위한 분산 스토리지 시스템으로 FoundationDB를 사용한다. FoundationDB는 키-값 저장소 인터페이스를 제공하며, Serializable Snapshot Isolation(SSI)을 통한 트랜잭션을 지원한다. 3FS는 모든 메타데이터를 FoundationDB의 키-값 쌍으로 저장한다. 메타데이터 서비스는 상태 비저장(stateless) 아키텍처를 따르므로, 관리자가 서비스를 중단 없이 원활하게 업그레이드하거나 재시작할 수 있어 유지보수성이 크게 향상된다. 클라이언트가 요청 실패 또는 타임아웃을 경험하면 자동으로 다른 사용 가능한 서비스로 장애 조치(failover)된다.

파일 시스템 메타데이터는 주로 두 가지 핵심 구조로 구성된다: inode와 디렉토리 엔트리이다. inode는 파일, 디렉토리, 심볼릭 링크의 속성 정보를 저장하며, 각각은 단조 증가하는 전역적으로 고유한 64비트 식별자로 구분된다. inode 키는 "INOD" 접두사와 inode id를 연결하여 구성되며, 이는 inodes가 여러 FoundationDB 노드에 걸쳐 분산되도록 하기 위함이다. inode의 값은 그 유형에 따라 달라진다:

-   모든 inode 유형은 소유권, 권한, 접근/수정/변경 시간 등의 기본 속성을 포함한다.
-   파일 inode의 추가 속성: 파일 길이, 청크 크기, 체인 테이블 내 선택된 범위, 섞기 시드.
-   디렉토리 inode의 추가 속성: 상위 디렉토리의 inode id, 하위 디렉토리/파일에 대한 기본 레이아웃 구성(체인 테이블, 청크 크기, 스트라이프 크기). 상위 inode id는 디렉토리 이동 시 루프(loop)를 감지하기 위해 필요하다. 예를 들어 `dir_a/dir_b`를 `dir_c/`로 이동할 때, `dir_c`가 `dir_b`의 하위 디렉토리가 아님을 확인해야 한다. 이는 `dir_c`의 모든 상위 디렉토리를 확인하여 달성할 수 있다.
-   심볼릭 링크 inode의 추가 속성: 대상 경로 문자열.

디렉토리 엔트리 키는 "DENT" 접두사, 상위 inode ID, 그리고 엔트리 이름으로 구성된다. 디렉토리 엔트리 값은 대상 inode id와 inode 유형을 저장한다. 디렉토리 내의 모든 엔트리는 자연스럽게 연속적인 키 범위를 형성하여, 범위 쿼리를 통한 디렉토리 목록 조회를 효율적으로 한다.

메타 작업은 FoundationDB의 트랜잭션을 활용한다:

-   메타데이터 조회를 위한 읽기 전용 트랜잭션: fstat, lookup, listdir 등.
-   메타데이터 갱신을 위한 읽기-쓰기 트랜잭션: create, link, unlink, rename 등.

쓰기 트랜잭션의 경우, FoundationDB는 충돌 감지를 위해 읽기/쓰기 키 집합을 추적한다. 동시 트랜잭션 충돌이 감지되면, 메타 서비스는 자동으로 트랜잭션을 재시도한다. 이 설계는 여러 메타 서비스가 병렬로 요청을 처리하면서 파일 시스템 메타데이터의 일관성을 유지할 수 있게 한다.

### 동적 파일 속성

대부분의 로컬 파일 시스템에서는 열린 파일을 삭제하더라도 관련된 모든 파일 디스크립터가 닫힐 때까지 삭제가 연기된다. 따라서 해당 파일의 모든 파일 디스크립터를 추적해야 한다. 학습 작업은 시작 시 많은 수의 파일을 열게 되는데, 모든 파일 디스크립터를 저장하면 메타 서비스와 FoundationDB에 과도한 부하가 발생한다. 학습 작업은 이 기능에 의존하지 않기 때문에, 3FS는 읽기 전용 모드로 열린 파일의 파일 디스크립터를 추적하지 않는다.

3FS는 쓰기 모드로 열린 각 파일 디스크립터(fd)에 대해 파일 세션을 유지한다. 쓰기 모드로 열린 파일을 삭제할 경우, 동시 쓰기로 인해 회수할 수 없는 쓰레기 청크가 발생할 수 있기 때문이다. 활성 쓰기 세션이 있는 파일이 삭제되면, 메타 서비스는 모든 fd가 닫힐 때까지 삭제를 지연시킨다. 오프라인 클라이언트에 의한 세션 잔존을 방지하기 위해, 3FS 메타 서비스는 주기적으로 클라이언트의 생존 여부를 확인하고 오프라인 클라이언트의 세션을 정리한다.

파일 길이는 inode에 저장된다. 활성 업데이트 중인 파일의 경우, inode에 저장된 길이가 실제 길이와 다를 수 있다. 쓰기 모드로 열린 각 파일에 대해 클라이언트는 주기적으로(기본 5초 간격) 최대 쓰기 위치를 메타 서비스에 보고한다. 만약 이 위치가 inode에 저장된 길이보다 크고 동시의 truncate 작업이 없다면, 이 위치가 새로운 파일 길이로 채택된다.

여러 클라이언트에 의한 동일 파일 길이의 동시 업데이트 가능성 때문에, 위에서 설명한 방식은 파일 길이에 대해 결국 일관성(eventual consistency)만을 보장한다. close/fsync 작업을 처리할 때, 메타 서비스는 스토리지 서비스로부터 마지막 청크의 ID와 길이를 조회하여 정확한 파일 길이를 얻는다. 파일 데이터가 여러 체인에 걸쳐 스트라이프되어 있기 때문에, 이 작업은 무시할 수 없는 오버헤드를 발생시킨다.

여러 메타 서비스에 의한 동일 파일 길이의 동시 업데이트는 트랜잭션 충돌을 야기하여 파일 길이 계산을 반복하게 만들 수 있다. 이를 완화하기 위해, 메타 서비스는 inode ID와 rendezvous 해시 알고리즘을 사용하여 파일 길이 업데이트 작업을 여러 메타 서비스에 분산시킨다.

우리의 프로덕션 환경에서는 스트라이프 크기가 크게 설정되어 있다: 200. 소형 파일의 경우, 파일 청크가 배치되는 체인의 수는 이 값보다 훨씬 적다. 잠재적으로 사용되는 체인의 수는 파일 inode에 저장되며, 파일 길이 업데이트 시 힌트로 사용된다. 이 값은 초기 16으로 시작하여, 추가 청크가 더 많은 체인에 기록될 때마다 두 배씩 증가한다. 이를 통해 소형 파일의 길이를 업데이트할 때 200개의 체인을 모두 조회하지 않아도 된다. 이 최적화는 소형 파일 삭제 시에도 확장될 수 있다.

## 청크 스토리지 시스템

청크 스토리지 시스템의 설계 목표는 스토리지 매체의 장애가 발생하더라도 가능한 최대 대역폭을 달성하는 것이다. 3FS의 읽기/쓰기 처리량은 클라이언트와 스토리지 서비스 간의 SSD 수와 양방향 네트워크 대역폭에 비례하여 선형적으로 확장되어야 한다. 애플리케이션은 지역성(locality)에 구애받지 않고 스토리지 서비스에 접근한다.

### 데이터 배치

각 파일 청크는 체인 복제 방식을 사용하여 복제된다. CRAQ에서는 쓰기 요청이 체인의 헤드(target)에 전달된 후 체인을 따라 전파된다. 읽기 요청은 체인의 어느 스토리지 타겟으로든 보낼 수 있다. 일반적으로 부하 분산을 위해 읽기 트래픽은 체인의 모든 타겟에 고르게 분산된다. 각 SSD에는 여러 스토리지 타겟이 생성되며, 이 타겟들은 서로 다른 체인에 참여한다.

예를 들어, 6개의 노드 A, B, C, D, E, F가 있고, 각 노드에는 1개의 SSD가 있다. 각 SSD에서 5개의 스토리지 타겟(1, 2, …, 5)을 생성하면 총 30개의 타겟(A1, A2, A3, …, F5)이 생긴다. 각 청크가 3개의 복제본을 가진다면, 체인 테이블은 아래와 같이 구성된다.

| 체인 | 버전 | 타겟 1 (헤드) | 타겟 2 | 타겟 3 (테일) |
| :---: | :-----: | :-------------: | :------: | :-------------: |
|   1   |    1    |      `A1`       |   `B1`   |      `C1`       |
|   2   |    1    |      `D1`       |   `E1`   |      `F1`       |
|   3   |    1    |      `A2`       |   `B2`   |      `C2`       |
|   4   |    1    |      `D2`       |   `E2`   |      `F2`       |
|   5   |    1    |      `A3`       |   `B3`   |      `C3`       |
|   6   |    1    |      `D3`       |   `E3`   |      `F3`       |
|   7   |    1    |      `A4`       |   `B4`   |      `C4`       |
|   8   |    1    |      `D4`       |   `E4`   |      `F4`       |
|   9   |    1    |      `A5`       |   `B5`   |      `C5`       |
|  10   |    1    |      `D5`       |   `E5`   |      `F5`       |

각 체인에는 버전 번호가 있으며, 체인이 변경(예: 스토리지 타겟 장애 등)되면 버전 번호가 증가한다. 체인 테이블의 변경은 기본 클러스터 관리자에 의해서만 이루어진다.

여러 가지 데이터 배치 요구 사항을 지원하기 위해 여러 체인 테이블을 구성할 수 있다. 예를 들어, 오프라인/배치 작업을 위한 체인 테이블과 온라인 서비스를 위한 체인 테이블을 각각 구성할 수 있다. 두 테이블은 상호 배타적인 노드와 SSD 상의 스토리지 타겟으로 구성된다.

논리적으로 각 체인의 상태는 독립적으로 변경된다. 각 체인은 여러 체인 테이블에 포함될 수 있다. 체인 테이블이라는 개념은 메타데이터 서비스가 파일마다 테이블을 선택하고, 해당 테이블 내의 체인에 따라 파일 청크를 스트라이프할 수 있도록 하기 위해 만들어졌다.

### 복구 중 균형 잡힌 트래픽 분배

위 체인 테이블에서 읽기 트래픽이 모든 스토리지 타겟에 고르게 분배된다고 가정하자. 만약 A가 실패하면, A의 읽기 요청은 B와 C로 재전달된다. 무거운 부하 상황에서 B와 C의 읽기 대역폭은 즉시 포화되고, 이들이 전체 시스템의 병목이 된다. 실패한 SSD를 교체하고 새로운 SSD로 데이터를 동기화하는 데 몇 시간이 걸릴 수 있으므로, 이 기간 동안 읽기 처리량이 저하된다.

성능 영향을 줄이기 위해, 더 많은 SSD가 재전달되는 트래픽을 분담하도록 할 수 있다. 아래의 체인 테이블에서는 A가 다른 모든 SSD와 짝을 이룬다. A가 실패하면, 다른 SSD들은 A의 읽기 트래픽의 1/5씩을 받게 된다.

| 체인 | 버전 | 타겟 1 (헤드) | 타겟 2 | 타겟 3 (테일) |
| :---: | :-----: | :-------------: | :------: | :-------------: |
|   1   |    1    |      `B1`       |   `E1`   |      `F1`       |
|   2   |    1    |      `A1`       |   `B2`   |      `D1`       |
|   3   |    1    |      `A2`       |   `D2`   |      `F2`       |
|   4   |    1    |      `C1`       |   `D3`   |      `E2`       |
|   5   |    1    |      `A3`       |   `C2`   |      `F3`       |
|   6   |    1    |      `A4`       |   `B3`   |      `E3`       |
|   7   |    1    |      `B4`       |   `C3`   |      `F4`       |
|   8   |    1    |      `B5`       |   `C4`   |      `E4`       |
|   9   |    1    |      `A5`       |   `C5`   |      `D4`       |
|  10   |    1    |      `D5`       |   `E5`   |      `F5`       |

최대의 읽기 처리량을 복구 중에 달성하기 위해, 부하 분산 문제는 불완전 블록 디자인(Balanced Incomplete Block Design)으로 공식화될 수 있다. 최적의 해(solution)는 정수 프로그래밍(integer programming) 솔버를 사용하여 얻어진다.

### 데이터 복제

CRAQ는 읽기 작업이 많은 워크로드에 최적화된 “모두 쓰고 어느 곳에서나 읽기” 복제 프로토콜이다. 모든 복제본의 읽기 대역폭을 활용하는 것은 올 플래시 스토리지 시스템에서 최고 읽기 처리량을 달성하는 데 매우 중요하다.

스토리지 서비스가 쓰기 요청을 받으면 다음과 같은 단계로 진행된다:

1.  서비스는 쓰기 요청에 포함된 체인 버전이 최신 버전과 일치하는지 확인한다. 일치하지 않을 경우 요청을 거부한다. 쓰기 요청은 클라이언트나 체인 내의 이전 노드로부터 전달될 수 있다.

2.  서비스는 RDMA Read 연산을 통해 쓰기 데이터를 가져온다. 만약 클라이언트 또는 이전 노드에 장애가 발생하면, RDMA Read 연산이 타임아웃되고 쓰기가 중단된다.

3.  쓰기 데이터가 로컬 메모리 버퍼로 가져와지면, 해당 청크 업데이트를 위한 락을 락 매니저로부터 획득한다. 동일 청크에 대한 동시 쓰기는 차단된다. 모든 쓰기는 헤드 타겟에서 직렬화된다.

4.  서비스는 메모리 내에 커밋된 버전의 청크를 읽어온 후, 업데이트를 적용하고 이를 pending 버전으로 저장한다. 스토리지 타겟은 청크에 대해 커밋된 버전과 pending 버전, 두 가지 버전을 저장할 수 있다. 각 버전은 단조 증가하는 버전 번호를 가진다. 커밋된 버전과 pending 버전의 버전 번호는 각각 `v`와 `u`이며, `u = v + 1`을 만족한다.

5.  만약 해당 서비스가 체인의 테일이면, pending 버전으로 커밋된 버전을 원자적으로 대체한 후 이전 노드에 확인(acknowledgment) 메시지를 전송한다. 그렇지 않으면, 쓰기 요청을 후임 노드로 전달한다. 커밋된 버전이 업데이트되면, 현재 체인 버전이 청크 메타데이터의 필드에 저장된다.

6.  스토리지 서비스가 확인 메시지를 수신하면, 로컬에서 커밋된 버전을 pending 버전으로 교체하고, 그 메시지를 이전 노드로 전파한다. 이후 로컬 청크 락을 해제한다.

예를 들어, 체인에 3개의 타겟 `A, B, C`가 있을 때, 쓰기 요청이 `A`에서 단계 5에 막 도달했다고 하자. `A`는 요청을 후임인 `B`에 전달한다. 그 후 `B`가 즉시 장애가 발생하여 전달된 쓰기 요청이 소실된다. 클러스터 관리자가 `B`의 장애를 감지하면, `B`를 오프라인으로 표시하고 체인 끝으로 이동시킨 후 업데이트된 체인 테이블을 방송한다. `A`가 최신 체인 테이블을 수신하면, 새 후임인 `C`에 쓰기 요청을 전달한다. `C`는 아직 최신 체인 테이블을 수신하지 못해 요청을 거부할 수 있으나, `A`는 계속 `C`에 요청을 전달할 수 있다. 결국 `C`는 최신 체인 테이블을 받아들여 요청을 승인한다.

읽기 요청이 스토리지 서비스에 도착하면:

1.  서비스가 청크의 커밋된 버전만 보유하고 있을 경우, 해당 버전을 클라이언트에게 반환한다.

2.  CRAQ와 달리, 당 구현에서는 테일 타겟에 버전 질의를 수행하지 않는다. 만약 커밋된 버전과 pending 버전이 모두 존재할 경우, 서비스는 클라이언트에게 특수 상태 코드를 응답하여 알린다. 클라이언트는 잠시 대기 후 재시도하거나, relaxed read 요청을 통해 pending 버전을 획득할 수 있다.

### 장애 감지

클러스터 관리자는 하트비트를 통해 fail-stop 장애를 감지한다. 클러스터 관리자는 설정된 간격(예: T초) 동안 하트비트를 받지 못한 서비스를 장애로 간주한다. 또한, 서비스가 T/2초 동안 클러스터 관리자와 통신하지 못하면 요청 처리를 중단하고 종료된다. 하트비트는 관리자로부터 부여받은 임대(lease)를 갱신하는 요청으로 볼 수 있다.

메타데이터 서비스는 상태 비저장이며, 클러스터 관리자가 제공하는 온라인 메타 서비스 목록은 클라이언트가 메타데이터 서비스에 연결할 수 있도록 하는 단순한 서비스 검색 메커니즘이다. 한 메타데이터 서비스가 다운되면, 클라이언트는 다른 메타데이터 서비스로 전환할 수 있다.

클러스터 관리자는 스토리지 서비스의 멤버십 변경에서 더욱 중요한 역할을 한다. 클러스터 관리자는 체인 테이블과 스토리지 타겟 상태에 대한 전역 뷰를 유지한다. 각 스토리지 타겟은 공개 상태(public state)와 로컬 상태(local state)를 가진다.

공개 상태는 해당 타겟이 읽기 요청을 처리할 준비가 되었는지, 쓰기 요청이 해당 타겟으로 전파될 수 있는지를 나타낸다. 공개 상태는 체인 테이블에 저장되며 서비스와 클라이언트에게 배포된다.

| 공개 상태 | 읽기 | 쓰기 | 비고                                           |
| :----------- | :--: | :---: | :---------------------------------------------- |
| serving      |  Y   |   Y   | 서비스가 살아있으며 클라이언트 요청을 처리 중       |
| syncing      |  N   |   Y   | 서비스는 살아있으나 데이터 복구가 진행 중             |
| waiting      |  N   |   N   | 서비스는 살아있으나 아직 데이터 복구가 시작되지 않음   |
| lastsrv      |  N   |   N   | 서비스가 다운되었으며 마지막 서비스 타겟이었음       |
| offline      |  N   |   N   | 서비스 다운 또는 스토리지 매체 장애                |

로컬 상태는 스토리지 서비스와 클러스터 관리자만 알 수 있으며, 클러스터 관리자 메모리에 저장된다. 스토리지 타겟이 중간 정도의 장애를 겪으면, 관련 서비스는 하트비트에서 해당 타겟의 로컬 상태를 offline으로 설정한다. 스토리지 서비스가 다운되면, 해당 서비스가 관리하는 스토리지 타겟들이 offline으로 표시된다.

| 로컬 상태 | 비고                                                |
| :---------- | :--------------------------------------------------- |
| up-to-date  | 서비스가 살아있으며 클라이언트 요청을 처리 중            |
| online      | 서비스가 살아있으며 타겟이 syncing 또는 waiting 상태       |
| offline     | 서비스 다운 또는 스토리지 매체 장애                   |

스토리지 타겟은 로컬 상태에 따라 공개 상태가 변경될 수 있다. 로컬 상태는 트리거 이벤트의 역할을 한다. 클러스터 관리자는 주기적으로 모든 체인을 스캔하여, 체인 상 타겟들의 공개 상태를 상태 전이 표에 따라 업데이트한다.

-   체인 버전은 체인이 업데이트될 때마다 증가된다.

-   스토리지 타겟이 offline으로 표시되면, 해당 타겟은 체인 끝으로 이동된다.

-   스토리지 서비스가 로컬 스토리지 타겟의 공개 상태 중 lastsrv 또는 offline을 발견하면 즉시 종료된다. 이 경우, 해당 서비스는 네트워크 파티션 오류로 클러스터 관리자로부터 격리되었을 수 있다.

-   스토리지 타겟의 syncing 상태에 대한 데이터 복구가 완료되면, 스토리지 서비스는 이후 하트비트 메시지에서 해당 타겟의 로컬 상태를 up-to-date로 설정한다.

| 로컬 상태 | 현재 공개 상태       | 이전(Predecessor)의 공개 상태 | 다음 공개 상태   |
| :---------- | :------------------- | :------------------------- | :---------------- |
| up-to-date  | serving              | (어떤 상태든 상관없음)           | serving           |
|             | syncing              | (어떤 상태든 상관없음)           | serving           |
|             | waiting              | (어떤 상태든 상관없음)           | waiting           |
|             | lastsrv              | (어떤 상태든 상관없음)           | serving           |
|             | offline              | (어떤 상태든 상관없음)           | waiting           |
| online      | serving              | (어떤 상태든 상관없음)           | serving           |
|             | syncing              | serving                    | syncing           |
|             |                      | serving이 아님                | waiting           |
|             | waiting              | serving                    | syncing           |
|             |                      | serving이 아님                | waiting           |
|             | lastsrv              | (어떤 상태든 상관없음)           | serving           |
|             | offline              | (어떤 상태든 상관없음)           | waiting           |
| offline     | serving              | 선행 노드가 없음              | lastsrv           |
|             |                      | 선행 노드가 있음              | offline           |
|             | syncing              | (어떤 상태든 상관없음)           | offline           |
|             | waiting              | (어떤 상태든 상관없음)           | offline           |
|             | lastsrv              | (어떤 상태든 상관없음)           | lastsrv           |
|             | offline              | (어떤 상태든 상관없음)           | offline           |

### 데이터 복구

스토리지 서비스가 종료되거나(예: 프로세스 크래시 혹은 업그레이드 중 재시작), 또는 스토리지 매체에 장애가 발생하면, 관련 스토리지 타겟 모두가 offline으로 표시되고 체인 끝으로 이동된다. 서비스가 재시작되면, 각 타겟은 독립적으로 복구 과정을 시작한다. 전체 복구 과정은 정상 작업과 겹치며, 중단 시간을 최소화한다.

이전에 offline 상태였던 스토리지 서비스가 시작될 경우:

1.  서비스는 주기적으로 클러스터 관리자에게서 최신 체인 테이블을 가져온다. 단, 모든 스토리지 타겟이 최신 체인 테이블에서 offline으로 표시될 때까지 하트비트를 전송하지 않는다. 이는 모든 타겟이 데이터 복구 과정을 거치도록 보장한다.

2.  복구 중에 쓰기 요청이 도착하면, 해당 요청은 항상 전체 청크를 교체하는(full-chunk-replace) 쓰기 방식이다. 로컬에서 커밋된 버전이 업데이트되고, 기존의 pending 버전은 폐기된다. 현재 서비스가 테일인 경우, 이전 노드에 확인 메시지가 전송된다. 전체 상태는 연속적인 전체 청크 교체 쓰기(full-chunk-replace) 요청을 통해 복구 중인 서비스로 복사된다.

3.  스토리지 타겟의 데이터 복구가 시작되기 전에, 이전 노드는 복구 대상 서비스에 dump-chunkmeta 요청을 보낸다. 이후 서비스는 로컬 청크 메타데이터 저장소를 순회하며, 해당 타겟에 있는 모든 청크의 ID, 체인 버전, 커밋/pending 버전 번호를 수집하고, 이를 이전 노드에 응답으로 전송한다.

4.  sync-done 메시지가 도착하면, 서비스는 해당 스토리지 타겟이 up-to-date 상태임을 인지한다. 이후 하트비트 메시지에서 해당 타겟의 로컬 상태를 up-to-date로 설정한다.

이전에 offline 상태였던 후임 노드가 online 상태로 전환되면:

1.  서비스는 정상 쓰기 요청을 후임 노드로 전달하기 시작한다. 클라이언트는 청크의 일부만 업데이트할 수 있으나, 전달되는 쓰기 요청은 전체 청크를 포함해야 한다. 즉, 전체 청크 교체 쓰기(full-chunk-replace)여야 한다.

2.  서비스는 후임 노드에 dump-chunkmeta 요청을 전송한다. 후임 노드에서 해당 타겟의 모든 청크 메타데이터를 수신하면, 로컬 타겟의 청크 메타데이터와 비교하여 어떤 청크를 전송할지 결정한다.

3.  선택된 청크들은 전체 청크 교체 쓰기 요청(full-chunk-replace)을 통해 후임 노드로 전송된다.

    -   각 청크에 대해 먼저 청크 락을 획득한다.
    -   체인 버전, 커밋 버전 번호, 청크 내용이 읽혀지며, 후임 노드로 전체 청크 교체 요청을 통해 전송된다.
    -   청크 락을 해제한다.

4.  모든 필요한 청크 전송이 완료되면, 후임 노드에 sync-done 메시지가 전송된다.

청크 전송 여부를 결정하는 규칙은 다음과 같다:

-   로컬 타겟에만 청크가 존재하면, 해당 청크를 전송해야 한다.
-   원격 타겟에만 청크가 존재하면, 해당 청크는 삭제되어야 한다.
-   로컬 청크 복제본의 체인 버전이 원격 청크 복제본의 체인 버전보다 높으면, 해당 청크를 전송해야 한다.
-   로컬/원격 청크 복제본의 체인 버전은 동일하지만, 로컬의 커밋 버전 번호가 원격의 pending 버전 번호와 다르면, 해당 청크를 전송해야 한다.
-   그렇지 않으면, 두 청크 복제본은 동일하거나 진행 중인 쓰기 요청에 의해 업데이트되고 있는 상태이다.

### 청크와 메타데이터

파일 청크는 청크 엔진에 저장된다. 각 SSD에서 청크 엔진의 영구 저장소는 청크 데이터를 저장하는 고정 개수의 데이터 파일과, 청크 메타데이터 및 기타 시스템 정보를 유지하는 RocksDB 인스턴스로 구성된다. 추가로, 청크 엔진은 쿼리 성능 향상을 위해 청크 메타데이터의 인메모리 캐시를 유지한다. 빠른 신규 청크 할당을 위해 청크 할당기가 구현되어 있다. 청크 엔진 인터페이스는 다음 작업들을 통해 스레드 안전한 접근을 제공한다:

1.  *open/close*  
    RocksDB에서 메타데이터를 로드하고 청크 할당기 상태를 재구성하여 엔진을 초기화한다.

2.  *get*  
    해시맵 캐시를 통해 청크 메타데이터와 참조 카운트 핸들을 검색하여, 평균 O(1) 시간 복잡도로 동시 접근을 가능하게 한다.

3.  *update*  
    데이터 수정 전에 새로운 청크를 할당함으로써 복사-쓰기(COW) 의미론을 구현한다. 모든 핸들이 해제될 때까지 기존 청크는 읽기가 가능하다.

4.  *commit*  
    쓰기 배치를 통해 업데이트된 청크 메타데이터를 RocksDB에 커밋하여 원자적 업데이트를 보장하며, 청크 메타데이터 캐시를 동기적으로 갱신한다.

청크 데이터는 궁극적으로 물리적 블록에 저장된다. 물리적 블록 크기는 64KiB에서 64MiB까지 2의 거듭제곱 단위로 증가하며, 총 11개의 서로 다른 크기를 가진다. 할당기는 실제 청크 크기와 가장 근접한 크기의 물리적 블록을 할당한다. 각 물리적 블록 크기마다 리소스 풀이 구성되며, 각 풀은 256개의 물리 파일을 포함한다. 물리적 블록의 사용 상태는 비트맵을 통해 메모리에서 관리된다. 물리적 블록이 회수되면 해당 비트맵 플래그가 0으로 설정된다. 해당 블록의 실제 저장 공간은 그대로 유지되며, 이후 할당 시 우선 사용된다. 사용 가능한 물리적 블록이 없을 경우, `fallocate()`를 사용하여 물리 파일 내에 연속된 큰 공간을 할당하고 256개의 새로운 물리적 블록을 생성한다. 이 방식은 디스크 단편화를 줄이는 데 도움이 된다.

청크에 대해 쓰기 작업을 수행할 때, 할당기는 먼저 새로운 물리적 블록을 할당한다. 이후 시스템은 기존 청크 데이터를 버퍼로 읽어오고, 업데이트를 적용한 후 갱신된 버퍼를 새로 할당된 블록에 기록한다. append 작업에 대해서는 최적화가 이루어져, 기존 블록의 끝에 데이터를 제자리에서 직접 추가한다. 이후, 새로운 청크 메타데이터가 새 블록의 위치와 기존 청크 메타데이터를 바탕으로 구성된다. 그리고 나서, 새로운 청크 메타데이터와 새로운 물리적 블록 및 기존 물리적 블록의 상태가 RocksDB에 원자적으로 업데이트된다.

[^1]: https://elixir.bootlin.com/linux/v5.4.284/source/fs/fuse/file.c#L1573
